{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from torch.optim import Adam\n",
    "from mlearn.base import Field\n",
    "from mlearn.data.fileio import *\n",
    "from mlearn import base\n",
    "from mlearn.data import clean\n",
    "from mlearn.data.clean import Cleaner, Preprocessors\n",
    "from mlearn.data import loaders\n",
    "from mlearn.utils.metrics import Metrics\n",
    "from mlearn.modeling.multitask import EmbeddingLSTMClassifier\n",
    "from mlearn.data.dataset import GeneralDataset\n",
    "from mlearn.utils.early_stopping import EarlyStopping\n",
    "from mlearn.utils.pipeline import process_and_batch \n",
    "from mlearn.utils.train import train_mtl_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = Cleaner(processes = ['lower', 'url', 'hashtag'])\n",
    "pr = Preprocessors(liwc_dir = '/Users/pranavsood/Documents/GitHub/mlearn/Multitask-Abuse/data/')\n",
    "m = Metrics(['accuracy'], 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loading Oraby et al. (Sarcasm) (train): 100%|██████████| 9386/9386 [00:31<00:00, 302.23it/s]\n"
     ]
    }
   ],
   "source": [
    "## Slow version\n",
    "davidson = loaders.oraby_sarcasm(cleaners = cl.tokenize , data_path = '/Users/pranavsood/Documents/GitHub/mlearn/Multitask-Abuse/data/json', length = 200, label_processor = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loading Oraby et al. (Sarcasm) (train): 100%|██████████| 9386/9386 [00:25<00:00, 363.80it/s]\n"
     ]
    }
   ],
   "source": [
    "## Slow version\n",
    "hoover = loaders.oraby_sarcasm(cleaners = cl.tokenize , data_path = '/Users/pranavsood/Documents/GitHub/mlearn/Multitask-Abuse/data/json', length = 200,\n",
    "                        preprocessor = pr.word_token, label_processor = lambda x: x.split()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Building vocabulary (Oraby et al. (Sarcasm)): 100%|██████████| 7508/7508 [00:00<00:00, 95687.16it/s]\n",
      "Encoding vocabulary: 100%|██████████| 21721/21721 [00:00<00:00, 1082849.71it/s]\n",
      "Encode label vocab (Oraby et al. (Sarcasm)): 100%|██████████| 2/2 [00:00<00:00, 9467.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Davidson\n",
    "davidson.build_token_vocab(davidson.data)\n",
    "davidson.build_label_vocab(davidson.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Building vocabulary (Oraby et al. (Sarcasm)): 100%|██████████| 7508/7508 [00:00<00:00, 102387.91it/s]\n",
      "Encoding vocabulary: 100%|██████████| 21601/21601 [00:00<00:00, 1132967.70it/s]\n",
      "Encode label vocab (Oraby et al. (Sarcasm)): 100%|██████████| 2/2 [00:00<00:00, 2968.37it/s]\n"
     ]
    }
   ],
   "source": [
    "hoover.build_token_vocab(hoover.data)\n",
    "hoover.build_label_vocab(hoover.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'notsarc': 0, 'sarc': 1}\n{'notsarc': 0, 'sarc': 1}\n21603\n21723\n{'notsarc': 0, 'sarc': 1}\n{'notsarc': 0, 'sarc': 1}\n{'fields': ['text', 'label'], 'text': ['manslaughter', 'involves', 'a', 'direct', 'action', 'that', 'causes', 'an', 'unintentional', 'death', '.', 'miscarriage', 'is', 'involuntary', ';', 'besides', 'the', 'person', 'suffering', 'a', 'miscarriage', 'might', 'well', 'want', 'to', 'keep', 'the', 'baby', '.', 'to', 'equate', 'miscarriage', 'with', 'manslaughter', 'is', 'preposterous', '.'], 'original': 'Manslaughter involves a direct action that causes an unintentional death. Miscarriage is involuntary; besides the person suffering a miscarriage might well want to keep the baby. To equate miscarriage with manslaughter is preposterous.', 'label': 'notsarc'}\n{'fields': ['text', 'label'], 'text': ['then', 'you', 'would', 'want', 'me', 'to', 'be', 'something', 'god', 'did', 'not', 'create', 'me', 'to', 'be', '?', 'silly', ',', 'i', \"'d\", 'say', '!', 'humans', 'are', 'part', 'of', 'the', 'animal', 'kingdom', '.', 'mammals', 'if', 'i', 'remember', 'from', 'biology', '.', 'are', 'you', 'not', 'an', 'animal', '?', 'if', 'not', ',', 'maybe', 'the', 'mothership', 'will', 'come', 'and', 'pick', 'you', 'up', 'soon', '.'], 'original': \"Then you would want me to be something god did not create me to be? Silly, I 'd say! Humans are part of the animal kingdom. Mammals if I remember from biology. Are you not an animal? If not, maybe the mothership will come and pick you up soon.\", 'label': 'sarc'}\n"
     ]
    }
   ],
   "source": [
    "print(hoover.ltoi)\n",
    "print(davidson.ltoi)\n",
    "print(hoover.vocab_size())\n",
    "print(davidson.vocab_size())\n",
    "print(hoover.ltoi)\n",
    "print(davidson.ltoi)\n",
    "print(hoover.data[0].__dict__)\n",
    "print(davidson.data[0].__dict__)\n",
    "\n",
    "processed_dav_tr = process_and_batch(davidson, davidson.data, 32, onehot = False)\n",
    "processed_hoo_tr = process_and_batch(hoover, hoover.data, 32, onehot = False)\n",
    "processed_hoo_de = process_and_batch(hoover, hoover.dev, 32, onehot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmbeddingLSTMClassifier(input_dims = [int(hoover.vocab_size()), int(davidson.vocab_size())], shared_dim = 150,\n",
    "                          hidden_dims = [128, 128], output_dims = [hoover.label_count(), davidson.label_count()],\n",
    "                          no_layers = 1, dropout = 0.2, embedding_dims = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'emb-mtl-lstm'"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "optimizer = Adam(model.parameters(), lr=0.1)\n",
    "loss = nn.NLLLoss()\n",
    "model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mtl_epoch(model: base.ModelType, loss_f: base.Callable, loss_weights: base.DataType, optimizer: base.Callable,\n",
    "               metrics: object, batchers: base.List[base.Batch], batch_count: int, dataset_weights: base.List[float],\n",
    "               taskid2name: dict, epoch_no: int, clip: float = None, gpu: bool = True, **kwargs) -> None:\n",
    "    \"\"\"\n",
    "    Train one epoch of an MTL training loop.\n",
    "\n",
    "    :model (base.ModelType): Model in the process of being trained.\n",
    "    :loss_f (base.Callable): The loss function being used.\n",
    "    :loss_weights (base.DataType): Determines relative task importance When using multiple input/output functions.\n",
    "    :optimizer (base.Callable): The optimizer function used.\n",
    "    :metrics (object): Initialized Metrics object.\n",
    "    :batchers (base.List[base.Batch]): A list of batched objects.\n",
    "    :batch_count (int): The number of batchers to go through in each epoch.\n",
    "    :dataset_weights (base.List[float]): The probability with which each dataset is chosen to be trained on.\n",
    "    :taskid2name (dict): Dictionary mapping task ID to dataset name.\n",
    "    :epoch_no (int): The iteration of the epoch.\n",
    "    :clip (float, default = None): Use gradient clipping.\n",
    "    \"\"\"\n",
    "    with tqdm(range(batch_count), desc = 'Batch', leave = False) as loop:\n",
    "        label_count = 0\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for i, b in enumerate(loop):\n",
    "            # Select task and get batch\n",
    "            task_id = np.random.choice(range(len(batchers)), p = dataset_weights)\n",
    "            X, y = next(iter(batchers[task_id]))\n",
    "\n",
    "            if gpu:\n",
    "                X = X.cuda()\n",
    "                y = y.cuda()\n",
    "\n",
    "            # Do model training\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            scores = model(X, task_id, **kwargs)\n",
    "            loss = loss_f(scores, y) * loss_weights[task_id]\n",
    "            loss.backward()\n",
    "\n",
    "            if clip is not None:\n",
    "                torch.nn.utils.clip_grad_norm(model.parameters(), clip)  # Prevent exploding gradients\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            metrics.compute(torch.argmax(scores, dim = 1).tolist(), y.tolist())\n",
    "            label_count += len(y.cpu().tolist())\n",
    "            epoch_loss += loss.data.item()\n",
    "            metrics.loss = loss.data.item() / len(y)\n",
    "\n",
    "            # Write batch info\n",
    "            task_name = taskid2name[task_id]\n",
    "            #mtl_batch_writer(model = model, batch = i, metrics = metrics, task_name = task_name, epoch = epoch_no,\n",
    "            #                 **kwargs)\n",
    "\n",
    "            loop.set_postfix(batch_loss = f\"{metrics.get_last('loss'):.4f}\",\n",
    "                             epoch_loss = f\"{epoch_loss / label_count:.4f}\",\n",
    "                             task_score = f\"{metrics.last_display():.4f}\",\n",
    "                             task = task_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "Batch:  83%|████████▎ | 391/470 [01:49<00:21,  3.60it/s, batch_loss=0.1222, epoch_loss=0.1166, task=1, task_score=0.4688]\u001b[A\n",
      "Batch:  83%|████████▎ | 391/470 [01:50<00:21,  3.60it/s, batch_loss=0.1225, epoch_loss=0.1166, task=1, task_score=0.3750]\u001b[A\n",
      "Batch:  83%|████████▎ | 392/470 [01:50<00:21,  3.62it/s, batch_loss=0.1225, epoch_loss=0.1166, task=1, task_score=0.3750]\u001b[A\n",
      "Batch:  83%|████████▎ | 392/470 [01:50<00:21,  3.62it/s, batch_loss=0.1159, epoch_loss=0.1166, task=1, task_score=0.5000]\u001b[A\n",
      "Batch:  84%|████████▎ | 393/470 [01:50<00:21,  3.63it/s, batch_loss=0.1159, epoch_loss=0.1166, task=1, task_score=0.5000]\u001b[A\n",
      "Batch:  84%|████████▎ | 393/470 [01:50<00:21,  3.63it/s, batch_loss=0.1276, epoch_loss=0.1167, task=0, task_score=0.4375]\u001b[A\n",
      "Batch:  84%|████████▍ | 394/470 [01:50<00:20,  3.67it/s, batch_loss=0.1276, epoch_loss=0.1167, task=0, task_score=0.4375]\u001b[A\n",
      "Batch:  84%|████████▍ | 394/470 [01:50<00:20,  3.67it/s, batch_loss=0.1083, epoch_loss=0.1166, task=1, task_score=0.6562]\u001b[A\n",
      "Batch:  84%|████████▍ | 395/470 [01:50<00:20,  3.65it/s, batch_loss=0.1083, epoch_loss=0.1166, task=1, task_score=0.6562]\u001b[A\n",
      "Batch:  84%|████████▍ | 395/470 [01:51<00:20,  3.65it/s, batch_loss=0.1128, epoch_loss=0.1166, task=0, task_score=0.5938]\u001b[A\n",
      "Batch:  84%|████████▍ | 396/470 [01:51<00:19,  3.74it/s, batch_loss=0.1128, epoch_loss=0.1166, task=0, task_score=0.5938]\u001b[A\n",
      "Batch:  84%|████████▍ | 396/470 [01:51<00:19,  3.74it/s, batch_loss=0.1167, epoch_loss=0.1166, task=0, task_score=0.4375]\u001b[A\n",
      "Batch:  84%|████████▍ | 397/470 [01:51<00:20,  3.63it/s, batch_loss=0.1167, epoch_loss=0.1166, task=0, task_score=0.4375]\u001b[A\n",
      "Batch:  84%|████████▍ | 397/470 [01:51<00:20,  3.63it/s, batch_loss=0.1202, epoch_loss=0.1166, task=1, task_score=0.3750]\u001b[A\n",
      "Batch:  85%|████████▍ | 398/470 [01:51<00:20,  3.60it/s, batch_loss=0.1202, epoch_loss=0.1166, task=1, task_score=0.3750]\u001b[A\n",
      "Batch:  85%|████████▍ | 398/470 [01:51<00:20,  3.60it/s, batch_loss=0.1098, epoch_loss=0.1166, task=1, task_score=0.5625]\u001b[A\n",
      "Batch:  85%|████████▍ | 399/470 [01:51<00:19,  3.62it/s, batch_loss=0.1098, epoch_loss=0.1166, task=1, task_score=0.5625]\u001b[A\n",
      "Batch:  85%|████████▍ | 399/470 [01:52<00:19,  3.62it/s, batch_loss=0.1099, epoch_loss=0.1166, task=0, task_score=0.5938]\u001b[A\n",
      "Batch:  85%|████████▌ | 400/470 [01:52<00:18,  3.72it/s, batch_loss=0.1099, epoch_loss=0.1166, task=0, task_score=0.5938]\u001b[A\n",
      "Batch:  85%|████████▌ | 400/470 [01:52<00:18,  3.72it/s, batch_loss=0.1227, epoch_loss=0.1166, task=1, task_score=0.4375]\u001b[A\n",
      "Batch:  85%|████████▌ | 401/470 [01:52<00:18,  3.71it/s, batch_loss=0.1227, epoch_loss=0.1166, task=1, task_score=0.4375]\u001b[A\n",
      "Batch:  85%|████████▌ | 401/470 [01:52<00:18,  3.71it/s, batch_loss=0.1092, epoch_loss=0.1166, task=0, task_score=0.5938]\u001b[A\n",
      "Batch:  86%|████████▌ | 402/470 [01:52<00:18,  3.71it/s, batch_loss=0.1092, epoch_loss=0.1166, task=0, task_score=0.5938]\u001b[A\n",
      "Batch:  86%|████████▌ | 402/470 [01:53<00:18,  3.71it/s, batch_loss=0.1159, epoch_loss=0.1166, task=0, task_score=0.4062]\u001b[A\n",
      "Batch:  86%|████████▌ | 403/470 [01:53<00:17,  3.80it/s, batch_loss=0.1159, epoch_loss=0.1166, task=0, task_score=0.4062]\u001b[A\n",
      "Batch:  86%|████████▌ | 403/470 [01:53<00:17,  3.80it/s, batch_loss=0.1163, epoch_loss=0.1166, task=1, task_score=0.5312]\u001b[A\n",
      "Batch:  86%|████████▌ | 404/470 [01:53<00:17,  3.76it/s, batch_loss=0.1163, epoch_loss=0.1166, task=1, task_score=0.5312]\u001b[A\n",
      "Batch:  86%|████████▌ | 404/470 [01:53<00:17,  3.76it/s, batch_loss=0.1142, epoch_loss=0.1166, task=0, task_score=0.5000]\u001b[A\n",
      "Batch:  86%|████████▌ | 405/470 [01:53<00:16,  3.83it/s, batch_loss=0.1142, epoch_loss=0.1166, task=0, task_score=0.5000]\u001b[A\n",
      "Batch:  86%|████████▌ | 405/470 [01:53<00:16,  3.83it/s, batch_loss=0.1143, epoch_loss=0.1166, task=0, task_score=0.5000]\u001b[A\n",
      "Batch:  86%|████████▋ | 406/470 [01:53<00:16,  3.89it/s, batch_loss=0.1143, epoch_loss=0.1166, task=0, task_score=0.5000]\u001b[A\n",
      "Batch:  86%|████████▋ | 406/470 [01:54<00:16,  3.89it/s, batch_loss=0.1113, epoch_loss=0.1166, task=0, task_score=0.5625]\u001b[A\n",
      "Batch:  87%|████████▋ | 407/470 [01:54<00:16,  3.93it/s, batch_loss=0.1113, epoch_loss=0.1166, task=0, task_score=0.5625]\u001b[A\n",
      "Batch:  87%|████████▋ | 407/470 [01:54<00:16,  3.93it/s, batch_loss=0.1198, epoch_loss=0.1166, task=1, task_score=0.4375]\u001b[A\n",
      "Batch:  87%|████████▋ | 408/470 [01:54<00:16,  3.85it/s, batch_loss=0.1198, epoch_loss=0.1166, task=1, task_score=0.4375]\u001b[A\n",
      "Batch:  87%|████████▋ | 408/470 [01:54<00:16,  3.85it/s, batch_loss=0.1106, epoch_loss=0.1166, task=0, task_score=0.6562]\u001b[A\n",
      "Batch:  87%|████████▋ | 409/470 [01:54<00:16,  3.77it/s, batch_loss=0.1106, epoch_loss=0.1166, task=0, task_score=0.6562]\u001b[A\n",
      "Batch:  87%|████████▋ | 409/470 [01:54<00:16,  3.77it/s, batch_loss=0.1203, epoch_loss=0.1166, task=1, task_score=0.5000]\u001b[A\n",
      "Batch:  87%|████████▋ | 410/470 [01:54<00:16,  3.67it/s, batch_loss=0.1203, epoch_loss=0.1166, task=1, task_score=0.5000]\u001b[A\n",
      "Batch:  87%|████████▋ | 410/470 [01:55<00:16,  3.67it/s, batch_loss=0.1207, epoch_loss=0.1166, task=1, task_score=0.4688]\u001b[A\n",
      "Batch:  87%|████████▋ | 411/470 [01:55<00:16,  3.67it/s, batch_loss=0.1207, epoch_loss=0.1166, task=1, task_score=0.4688]\u001b[A\n",
      "Batch:  87%|████████▋ | 411/470 [01:55<00:16,  3.67it/s, batch_loss=0.1194, epoch_loss=0.1166, task=1, task_score=0.4375]\u001b[A\n",
      "Batch:  88%|████████▊ | 412/470 [01:55<00:15,  3.67it/s, batch_loss=0.1194, epoch_loss=0.1166, task=1, task_score=0.4375]\u001b[A\n",
      "Batch:  88%|████████▊ | 412/470 [01:55<00:15,  3.67it/s, batch_loss=0.1151, epoch_loss=0.1166, task=1, task_score=0.5625]\u001b[A\n",
      "Batch:  88%|████████▊ | 413/470 [01:55<00:15,  3.62it/s, batch_loss=0.1151, epoch_loss=0.1166, task=1, task_score=0.5625]\u001b[A\n",
      "Batch:  88%|████████▊ | 413/470 [01:55<00:15,  3.62it/s, batch_loss=0.1150, epoch_loss=0.1166, task=0, task_score=0.5000]\u001b[A\n",
      "Batch:  88%|████████▊ | 414/470 [01:55<00:15,  3.70it/s, batch_loss=0.1150, epoch_loss=0.1166, task=0, task_score=0.5000]\u001b[A\n",
      "Batch:  88%|████████▊ | 414/470 [01:56<00:15,  3.70it/s, batch_loss=0.1129, epoch_loss=0.1166, task=0, task_score=0.5000]\u001b[A\n",
      "Batch:  88%|████████▊ | 415/470 [01:56<00:14,  3.77it/s, batch_loss=0.1129, epoch_loss=0.1166, task=0, task_score=0.5000]\u001b[A\n",
      "Batch:  88%|████████▊ | 415/470 [01:56<00:14,  3.77it/s, batch_loss=0.1122, epoch_loss=0.1166, task=1, task_score=0.5938]\u001b[A\n",
      "Batch:  89%|████████▊ | 416/470 [01:56<00:14,  3.75it/s, batch_loss=0.1122, epoch_loss=0.1166, task=1, task_score=0.5938]\u001b[A\n",
      "Batch:  89%|████████▊ | 416/470 [01:56<00:14,  3.75it/s, batch_loss=0.1155, epoch_loss=0.1166, task=1, task_score=0.4062]\u001b[A\n",
      "Batch:  89%|████████▊ | 417/470 [01:56<00:14,  3.78it/s, batch_loss=0.1155, epoch_loss=0.1166, task=1, task_score=0.4062]\u001b[A\n",
      "Batch:  89%|████████▊ | 417/470 [01:56<00:14,  3.78it/s, batch_loss=0.1203, epoch_loss=0.1166, task=0, task_score=0.4062]\u001b[A\n",
      "Batch:  89%|████████▉ | 418/470 [01:56<00:13,  3.82it/s, batch_loss=0.1203, epoch_loss=0.1166, task=0, task_score=0.4062]\u001b[A\n",
      "Batch:  89%|████████▉ | 418/470 [01:57<00:13,  3.82it/s, batch_loss=0.1205, epoch_loss=0.1166, task=1, task_score=0.3438]\u001b[A\n",
      "Batch:  89%|████████▉ | 419/470 [01:57<00:13,  3.82it/s, batch_loss=0.1205, epoch_loss=0.1166, task=1, task_score=0.3438]\u001b[A\n",
      "Batch:  89%|████████▉ | 419/470 [01:57<00:13,  3.82it/s, batch_loss=0.1169, epoch_loss=0.1166, task=1, task_score=0.4062]\u001b[A\n",
      "Batch:  89%|████████▉ | 420/470 [01:57<00:13,  3.62it/s, batch_loss=0.1169, epoch_loss=0.1166, task=1, task_score=0.4062]\u001b[A\n",
      "Batch:  89%|████████▉ | 420/470 [01:57<00:13,  3.62it/s, batch_loss=0.1173, epoch_loss=0.1166, task=0, task_score=0.4688]\u001b[A\n",
      "Batch:  90%|████████▉ | 421/470 [01:57<00:13,  3.75it/s, batch_loss=0.1173, epoch_loss=0.1166, task=0, task_score=0.4688]\u001b[A\n",
      "Batch:  90%|████████▉ | 421/470 [01:58<00:13,  3.75it/s, batch_loss=0.1136, epoch_loss=0.1166, task=0, task_score=0.6250]\u001b[A\n",
      "Batch:  90%|████████▉ | 422/470 [01:58<00:12,  3.86it/s, batch_loss=0.1136, epoch_loss=0.1166, task=0, task_score=0.6250]\u001b[A\n",
      "Batch:  90%|████████▉ | 422/470 [01:58<00:12,  3.86it/s, batch_loss=0.1165, epoch_loss=0.1166, task=1, task_score=0.5938]\u001b[A\n",
      "Batch:  90%|█████████ | 423/470 [01:58<00:12,  3.84it/s, batch_loss=0.1165, epoch_loss=0.1166, task=1, task_score=0.5938]\u001b[A\n",
      "Batch:  90%|█████████ | 423/470 [01:58<00:12,  3.84it/s, batch_loss=0.1155, epoch_loss=0.1166, task=0, task_score=0.5625]\u001b[A\n",
      "Batch:  90%|█████████ | 424/470 [01:58<00:11,  3.94it/s, batch_loss=0.1155, epoch_loss=0.1166, task=0, task_score=0.5625]\u001b[A\n",
      "Batch:  90%|█████████ | 424/470 [01:58<00:11,  3.94it/s, batch_loss=0.1187, epoch_loss=0.1166, task=1, task_score=0.5625]\u001b[A\n",
      "Batch:  90%|█████████ | 425/470 [01:58<00:11,  3.91it/s, batch_loss=0.1187, epoch_loss=0.1166, task=1, task_score=0.5625]\u001b[A\n",
      "Batch:  90%|█████████ | 425/470 [01:59<00:11,  3.91it/s, batch_loss=0.1166, epoch_loss=0.1166, task=1, task_score=0.4375]\u001b[A\n",
      "Batch:  91%|█████████ | 426/470 [01:59<00:11,  3.82it/s, batch_loss=0.1166, epoch_loss=0.1166, task=1, task_score=0.4375]\u001b[A\n",
      "Batch:  91%|█████████ | 426/470 [01:59<00:11,  3.82it/s, batch_loss=0.1191, epoch_loss=0.1166, task=1, task_score=0.4375]\u001b[A\n",
      "Batch:  91%|█████████ | 427/470 [01:59<00:11,  3.84it/s, batch_loss=0.1191, epoch_loss=0.1166, task=1, task_score=0.4375]\u001b[A\n",
      "Batch:  91%|█████████ | 427/470 [01:59<00:11,  3.84it/s, batch_loss=0.1175, epoch_loss=0.1166, task=1, task_score=0.4688]\u001b[A\n",
      "Batch:  91%|█████████ | 428/470 [01:59<00:11,  3.80it/s, batch_loss=0.1175, epoch_loss=0.1166, task=1, task_score=0.4688]\u001b[A\n",
      "Batch:  91%|█████████ | 428/470 [01:59<00:11,  3.80it/s, batch_loss=0.1189, epoch_loss=0.1166, task=0, task_score=0.4375]\u001b[A\n",
      "Batch:  91%|█████████▏| 429/470 [01:59<00:10,  3.85it/s, batch_loss=0.1189, epoch_loss=0.1166, task=0, task_score=0.4375]\u001b[A\n",
      "Batch:  91%|█████████▏| 429/470 [02:00<00:10,  3.85it/s, batch_loss=0.1314, epoch_loss=0.1166, task=1, task_score=0.3750]\u001b[A\n",
      "Batch:  91%|█████████▏| 430/470 [02:00<00:10,  3.82it/s, batch_loss=0.1314, epoch_loss=0.1166, task=1, task_score=0.3750]\u001b[A\n",
      "Batch:  91%|█████████▏| 430/470 [02:00<00:10,  3.82it/s, batch_loss=0.1141, epoch_loss=0.1166, task=0, task_score=0.5625]\u001b[A\n",
      "Batch:  92%|█████████▏| 431/470 [02:00<00:10,  3.82it/s, batch_loss=0.1141, epoch_loss=0.1166, task=0, task_score=0.5625]\u001b[A\n",
      "Batch:  92%|█████████▏| 431/470 [02:00<00:10,  3.82it/s, batch_loss=0.1173, epoch_loss=0.1166, task=1, task_score=0.5312]\u001b[A\n",
      "Batch:  92%|█████████▏| 432/470 [02:00<00:10,  3.79it/s, batch_loss=0.1173, epoch_loss=0.1166, task=1, task_score=0.5312]\u001b[A\n",
      "Batch:  92%|█████████▏| 432/470 [02:00<00:10,  3.79it/s, batch_loss=0.1199, epoch_loss=0.1166, task=0, task_score=0.5312]\u001b[A\n",
      "Batch:  92%|█████████▏| 433/470 [02:00<00:09,  3.90it/s, batch_loss=0.1199, epoch_loss=0.1166, task=0, task_score=0.5312]\u001b[A\n",
      "Batch:  92%|█████████▏| 433/470 [02:01<00:09,  3.90it/s, batch_loss=0.1160, epoch_loss=0.1166, task=0, task_score=0.6250]\u001b[A\n",
      "Batch:  92%|█████████▏| 434/470 [02:01<00:09,  3.90it/s, batch_loss=0.1160, epoch_loss=0.1166, task=0, task_score=0.6250]\u001b[A\n",
      "Batch:  92%|█████████▏| 434/470 [02:01<00:09,  3.90it/s, batch_loss=0.1074, epoch_loss=0.1166, task=0, task_score=0.6250]\u001b[A\n",
      "Batch:  93%|█████████▎| 435/470 [02:01<00:08,  3.96it/s, batch_loss=0.1074, epoch_loss=0.1166, task=0, task_score=0.6250]\u001b[A\n",
      "Batch:  93%|█████████▎| 435/470 [02:01<00:08,  3.96it/s, batch_loss=0.1163, epoch_loss=0.1166, task=1, task_score=0.5625]\u001b[A\n",
      "Batch:  93%|█████████▎| 436/470 [02:01<00:08,  3.90it/s, batch_loss=0.1163, epoch_loss=0.1166, task=1, task_score=0.5625]\u001b[A\n",
      "Batch:  93%|█████████▎| 436/470 [02:01<00:08,  3.90it/s, batch_loss=0.1193, epoch_loss=0.1166, task=1, task_score=0.4688]\u001b[A\n",
      "Batch:  93%|█████████▎| 437/470 [02:01<00:08,  3.88it/s, batch_loss=0.1193, epoch_loss=0.1166, task=1, task_score=0.4688]\u001b[A\n",
      "Batch:  93%|█████████▎| 437/470 [02:02<00:08,  3.88it/s, batch_loss=0.1098, epoch_loss=0.1166, task=1, task_score=0.5625]\u001b[A\n",
      "Batch:  93%|█████████▎| 438/470 [02:02<00:08,  3.87it/s, batch_loss=0.1098, epoch_loss=0.1166, task=1, task_score=0.5625]\u001b[A\n",
      "Batch:  93%|█████████▎| 438/470 [02:02<00:08,  3.87it/s, batch_loss=0.1144, epoch_loss=0.1166, task=0, task_score=0.5312]\u001b[A\n",
      "Batch:  93%|█████████▎| 439/470 [02:02<00:08,  3.84it/s, batch_loss=0.1144, epoch_loss=0.1166, task=0, task_score=0.5312]\u001b[A\n",
      "Batch:  93%|█████████▎| 439/470 [02:02<00:08,  3.84it/s, batch_loss=0.1129, epoch_loss=0.1166, task=0, task_score=0.5625]\u001b[A\n",
      "Batch:  94%|█████████▎| 440/470 [02:02<00:07,  3.93it/s, batch_loss=0.1129, epoch_loss=0.1166, task=0, task_score=0.5625]\u001b[A\n",
      "Batch:  94%|█████████▎| 440/470 [02:02<00:07,  3.93it/s, batch_loss=0.1122, epoch_loss=0.1166, task=1, task_score=0.5312]\u001b[A\n",
      "Batch:  94%|█████████▍| 441/470 [02:02<00:07,  3.82it/s, batch_loss=0.1122, epoch_loss=0.1166, task=1, task_score=0.5312]\u001b[A\n",
      "Batch:  94%|█████████▍| 441/470 [02:03<00:07,  3.82it/s, batch_loss=0.1115, epoch_loss=0.1166, task=1, task_score=0.5625]\u001b[A\n",
      "Batch:  94%|█████████▍| 442/470 [02:03<00:07,  3.75it/s, batch_loss=0.1115, epoch_loss=0.1166, task=1, task_score=0.5625]\u001b[A\n",
      "Batch:  94%|█████████▍| 442/470 [02:03<00:07,  3.75it/s, batch_loss=0.1166, epoch_loss=0.1166, task=1, task_score=0.5625]\u001b[A\n",
      "Batch:  94%|█████████▍| 443/470 [02:03<00:07,  3.78it/s, batch_loss=0.1166, epoch_loss=0.1166, task=1, task_score=0.5625]\u001b[A\n",
      "Batch:  94%|█████████▍| 443/470 [02:03<00:07,  3.78it/s, batch_loss=0.1162, epoch_loss=0.1166, task=0, task_score=0.5000]\u001b[A\n",
      "Batch:  94%|█████████▍| 444/470 [02:03<00:06,  3.88it/s, batch_loss=0.1162, epoch_loss=0.1166, task=0, task_score=0.5000]\u001b[A\n",
      "Batch:  94%|█████████▍| 444/470 [02:03<00:06,  3.88it/s, batch_loss=0.1117, epoch_loss=0.1166, task=0, task_score=0.5938]\u001b[A\n",
      "Batch:  95%|█████████▍| 445/470 [02:03<00:06,  3.98it/s, batch_loss=0.1117, epoch_loss=0.1166, task=0, task_score=0.5938]\u001b[A\n",
      "Batch:  95%|█████████▍| 445/470 [02:04<00:06,  3.98it/s, batch_loss=0.1142, epoch_loss=0.1166, task=0, task_score=0.6250]\u001b[A\n",
      "Batch:  95%|█████████▍| 446/470 [02:04<00:05,  4.04it/s, batch_loss=0.1142, epoch_loss=0.1166, task=0, task_score=0.6250]\u001b[A\n",
      "Batch:  95%|█████████▍| 446/470 [02:04<00:05,  4.04it/s, batch_loss=0.1156, epoch_loss=0.1165, task=1, task_score=0.5000]\u001b[A\n",
      "Batch:  95%|█████████▌| 447/470 [02:04<00:05,  3.98it/s, batch_loss=0.1156, epoch_loss=0.1165, task=1, task_score=0.5000]\u001b[A\n",
      "Batch:  95%|█████████▌| 447/470 [02:04<00:05,  3.98it/s, batch_loss=0.1133, epoch_loss=0.1165, task=0, task_score=0.5000]\u001b[A\n",
      "Batch:  95%|█████████▌| 448/470 [02:04<00:05,  4.07it/s, batch_loss=0.1133, epoch_loss=0.1165, task=0, task_score=0.5000]\u001b[A\n",
      "Batch:  95%|█████████▌| 448/470 [02:04<00:05,  4.07it/s, batch_loss=0.1135, epoch_loss=0.1165, task=0, task_score=0.4688]\u001b[A\n",
      "Batch:  96%|█████████▌| 449/470 [02:04<00:05,  4.11it/s, batch_loss=0.1135, epoch_loss=0.1165, task=0, task_score=0.4688]\u001b[A\n",
      "Batch:  96%|█████████▌| 449/470 [02:05<00:05,  4.11it/s, batch_loss=0.1117, epoch_loss=0.1165, task=1, task_score=0.6250]\u001b[A\n",
      "Batch:  96%|█████████▌| 450/470 [02:05<00:05,  3.98it/s, batch_loss=0.1117, epoch_loss=0.1165, task=1, task_score=0.6250]\u001b[A\n",
      "Batch:  96%|█████████▌| 450/470 [02:05<00:05,  3.98it/s, batch_loss=0.1155, epoch_loss=0.1165, task=0, task_score=0.5625]\u001b[A\n",
      "Batch:  96%|█████████▌| 451/470 [02:05<00:04,  3.92it/s, batch_loss=0.1155, epoch_loss=0.1165, task=0, task_score=0.5625]\u001b[A\n",
      "Batch:  96%|█████████▌| 451/470 [02:05<00:04,  3.92it/s, batch_loss=0.1308, epoch_loss=0.1166, task=1, task_score=0.2500]\u001b[A\n",
      "Batch:  96%|█████████▌| 452/470 [02:05<00:04,  3.87it/s, batch_loss=0.1308, epoch_loss=0.1166, task=1, task_score=0.2500]\u001b[A\n",
      "Batch:  96%|█████████▌| 452/470 [02:05<00:04,  3.87it/s, batch_loss=0.1131, epoch_loss=0.1165, task=0, task_score=0.4688]\u001b[A\n",
      "Batch:  96%|█████████▋| 453/470 [02:05<00:04,  3.96it/s, batch_loss=0.1131, epoch_loss=0.1165, task=0, task_score=0.4688]\u001b[A\n",
      "Batch:  96%|█████████▋| 453/470 [02:06<00:04,  3.96it/s, batch_loss=0.1153, epoch_loss=0.1165, task=1, task_score=0.4688]\u001b[A\n",
      "Batch:  97%|█████████▋| 454/470 [02:06<00:04,  3.92it/s, batch_loss=0.1153, epoch_loss=0.1165, task=1, task_score=0.4688]\u001b[A\n",
      "Batch:  97%|█████████▋| 454/470 [02:06<00:04,  3.92it/s, batch_loss=0.1182, epoch_loss=0.1165, task=1, task_score=0.4688]\u001b[A\n",
      "Batch:  97%|█████████▋| 455/470 [02:06<00:03,  3.88it/s, batch_loss=0.1182, epoch_loss=0.1165, task=1, task_score=0.4688]\u001b[A\n",
      "Batch:  97%|█████████▋| 455/470 [02:06<00:03,  3.88it/s, batch_loss=0.1172, epoch_loss=0.1165, task=0, task_score=0.5312]\u001b[A\n",
      "Batch:  97%|█████████▋| 456/470 [02:06<00:03,  3.95it/s, batch_loss=0.1172, epoch_loss=0.1165, task=0, task_score=0.5312]\u001b[A\n",
      "Batch:  97%|█████████▋| 456/470 [02:07<00:03,  3.95it/s, batch_loss=0.1144, epoch_loss=0.1165, task=0, task_score=0.5312]\u001b[A\n",
      "Batch:  97%|█████████▋| 457/470 [02:07<00:03,  3.99it/s, batch_loss=0.1144, epoch_loss=0.1165, task=0, task_score=0.5312]\u001b[A\n",
      "Batch:  97%|█████████▋| 457/470 [02:07<00:03,  3.99it/s, batch_loss=0.1099, epoch_loss=0.1165, task=1, task_score=0.5938]\u001b[A\n",
      "Batch:  97%|█████████▋| 458/470 [02:07<00:03,  3.88it/s, batch_loss=0.1099, epoch_loss=0.1165, task=1, task_score=0.5938]\u001b[A\n",
      "Batch:  97%|█████████▋| 458/470 [02:07<00:03,  3.88it/s, batch_loss=0.1109, epoch_loss=0.1165, task=1, task_score=0.5625]\u001b[A\n",
      "Batch:  98%|█████████▊| 459/470 [02:07<00:02,  3.78it/s, batch_loss=0.1109, epoch_loss=0.1165, task=1, task_score=0.5625]\u001b[A\n",
      "Batch:  98%|█████████▊| 459/470 [02:07<00:02,  3.78it/s, batch_loss=0.1150, epoch_loss=0.1165, task=0, task_score=0.5312]\u001b[A\n",
      "Batch:  98%|█████████▊| 460/470 [02:07<00:02,  3.89it/s, batch_loss=0.1150, epoch_loss=0.1165, task=0, task_score=0.5312]\u001b[A\n",
      "Batch:  98%|█████████▊| 460/470 [02:08<00:02,  3.89it/s, batch_loss=0.1151, epoch_loss=0.1165, task=0, task_score=0.5625]\u001b[A\n",
      "Batch:  98%|█████████▊| 461/470 [02:08<00:02,  3.98it/s, batch_loss=0.1151, epoch_loss=0.1165, task=0, task_score=0.5625]\u001b[A\n",
      "Batch:  98%|█████████▊| 461/470 [02:08<00:02,  3.98it/s, batch_loss=0.1174, epoch_loss=0.1165, task=1, task_score=0.4688]\u001b[A\n",
      "Batch:  98%|█████████▊| 462/470 [02:08<00:02,  3.72it/s, batch_loss=0.1174, epoch_loss=0.1165, task=1, task_score=0.4688]\u001b[A\n",
      "Batch:  98%|█████████▊| 462/470 [02:08<00:02,  3.72it/s, batch_loss=0.1130, epoch_loss=0.1165, task=0, task_score=0.3750]\u001b[A\n",
      "Batch:  99%|█████████▊| 463/470 [02:08<00:01,  3.82it/s, batch_loss=0.1130, epoch_loss=0.1165, task=0, task_score=0.3750]\u001b[A\n",
      "Batch:  99%|█████████▊| 463/470 [02:08<00:01,  3.82it/s, batch_loss=0.1134, epoch_loss=0.1165, task=0, task_score=0.6250]\u001b[A\n",
      "Batch:  99%|█████████▊| 464/470 [02:08<00:01,  3.89it/s, batch_loss=0.1134, epoch_loss=0.1165, task=0, task_score=0.6250]\u001b[A\n",
      "Batch:  99%|█████████▊| 464/470 [02:09<00:01,  3.89it/s, batch_loss=0.1253, epoch_loss=0.1165, task=0, task_score=0.4375]\u001b[A\n",
      "Batch:  99%|█████████▉| 465/470 [02:09<00:01,  3.95it/s, batch_loss=0.1253, epoch_loss=0.1165, task=0, task_score=0.4375]\u001b[A\n",
      "Batch:  99%|█████████▉| 465/470 [02:09<00:01,  3.95it/s, batch_loss=0.1192, epoch_loss=0.1165, task=1, task_score=0.4062]\u001b[A\n",
      "Batch:  99%|█████████▉| 466/470 [02:09<00:01,  3.84it/s, batch_loss=0.1192, epoch_loss=0.1165, task=1, task_score=0.4062]\u001b[A\n",
      "Batch:  99%|█████████▉| 466/470 [02:09<00:01,  3.84it/s, batch_loss=0.1113, epoch_loss=0.1165, task=0, task_score=0.5625]\u001b[A\n",
      "Batch:  99%|█████████▉| 467/470 [02:09<00:00,  3.89it/s, batch_loss=0.1113, epoch_loss=0.1165, task=0, task_score=0.5625]\u001b[A\n",
      "Batch:  99%|█████████▉| 467/470 [02:09<00:00,  3.89it/s, batch_loss=0.1178, epoch_loss=0.1165, task=0, task_score=0.3750]\u001b[A\n",
      "Batch: 100%|█████████▉| 468/470 [02:09<00:00,  4.00it/s, batch_loss=0.1178, epoch_loss=0.1165, task=0, task_score=0.3750]\u001b[A\n",
      "Batch: 100%|█████████▉| 468/470 [02:10<00:00,  4.00it/s, batch_loss=0.1111, epoch_loss=0.1165, task=0, task_score=0.5938]\u001b[A\n",
      "Batch: 100%|█████████▉| 469/470 [02:10<00:00,  4.06it/s, batch_loss=0.1111, epoch_loss=0.1165, task=0, task_score=0.5938]\u001b[A\n",
      "Batch: 100%|█████████▉| 469/470 [02:10<00:00,  4.06it/s, batch_loss=0.1236, epoch_loss=0.1165, task=1, task_score=0.5312]\u001b[A\n",
      "Batch: 100%|██████████| 470/470 [02:10<00:00,  4.00it/s, batch_loss=0.1236, epoch_loss=0.1165, task=1, task_score=0.5312]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "train_model(model, [processed_hoo_tr, processed_dav_tr], optimizer, loss, dev_data = processed_hoo_de, metrics = m, gpu = False) # 2 min 10s with my code , "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import trange\n",
    "\n",
    "def train_model(model: base.ModelType, batchers: base.List[base.DataType], optimizer: base.Callable,\n",
    "                    loss: base.Callable, metrics: object, batch_size: int = 64, epochs: int = 2, clip: float = None,\n",
    "                    earlystop: int = None, save_path: str = None, dev: base.DataType = None, dev_metrics: object = None,\n",
    "                    dev_task_id: int = 0, batches_per_epoch: int = None, low: bool = True,\n",
    "                    shuffle: bool = True, dataset_weights: base.DataType = None, loss_weights: base.DataType = None,\n",
    "                    gpu: bool = True, hyperopt = None, **kwargs) -> None:\n",
    "    \"\"\"\n",
    "    Train a multi-task learning model.\n",
    "\n",
    "    :model (base.ModelType): Untrained model.\n",
    "    :batchers (base.List[base.DataType]): Batched training data.\n",
    "    :save_path (str): Path to save trained model to.\n",
    "    :optimizer (base.Callable): Pytorch optimizer to train model.\n",
    "    :loss (base.Callable): Loss function.\n",
    "    :metrics (object): Initialized metrics object.\n",
    "    :batch_size (int): Training batch size.\n",
    "    :epochs (int): Maximum number of epochs (if no early stopping).\n",
    "    :clip (float, default = None): Use gradient clipping.\n",
    "    :earlystop (int, default = None): Number of epochs to observe non-improving dev performance before early stopping.\n",
    "    :dev (base.DataType): Batched dev object.\n",
    "    :dev_metrics (object): Initialized dev_metrics object.\n",
    "    :dev_task_id (int, default = 0): Task ID for task to use for early stopping, in case of multitask learning.\n",
    "    :batches_per_epoch (int, default = None): Set number of batchers per epoch. If None, an epoch consists of all\n",
    "                                              training examples.\n",
    "    :low (bool, default = True): If lower value is to be interpreted as better by EarlyStopping.\n",
    "    :shuffle: Whether to shuffle data at training.\n",
    "    :dataset_weights (base.DataType, default = None): Probability for each dataset to be chosen (must sum to 1.0).\n",
    "    :loss_weights (base.DataType, default = None): Weight the loss by multiplication.\n",
    "    :gpu (bool, default = True): Set tot rue if model runs on GPU.\n",
    "    :hyperopt (default = None): Trial object for hyper parameter search.\n",
    "    \"\"\"\n",
    "    with trange(epochs, desc = \"Training model\", leave = False) as loop:\n",
    "        taskid2name = {i: batchers[i].data.name for i in range(len(batchers))}\n",
    "        scores = defaultdict(list)\n",
    "\n",
    "        if gpu:\n",
    "            model = model.cuda()\n",
    "\n",
    "        if loss_weights is None:\n",
    "            loss_weights = np.ones(len(batchers))\n",
    "\n",
    "        if dataset_weights is None:\n",
    "            dataset_weights = np.ones(len(batchers)) / len(batchers)\n",
    "\n",
    "        if batches_per_epoch is None:\n",
    "            batches_per_epoch = sum([len(dataset) * batch_size for dataset in batchers]) // batch_size\n",
    "\n",
    "        if earlystop is not None:\n",
    "            earlystop = EarlyStopping(save_path, model, earlystop, low_is_good = low)\n",
    "\n",
    "        for i, epoch in enumerate(loop):\n",
    "            if shuffle:\n",
    "                for batch in batchers:\n",
    "                    batch.shuffle()\n",
    "\n",
    "            _mtl_epoch(model, loss, loss_weights, optimizer, metrics, batchers, batches_per_epoch, dataset_weights,\n",
    "                       taskid2name, i, clip, gpu = gpu, **kwargs)\n",
    "\n",
    "            for score in metrics.scores:  # Compute average value of the scores computed in each epoch.\n",
    "                if score == 'loss':\n",
    "                    scores[score].append(sum(metrics.scores[score]))\n",
    "                else:\n",
    "                    scores[score].append(np.mean(metrics.scores[score]))\n",
    "\n",
    "            try:\n",
    "                eval_torch_model(model, dev, loss, dev_metrics, mtl = dev_task_id, store = False, gpu = gpu, **kwargs)\n",
    "\n",
    "                loop.set_postfix(loss = f\"{metrics.get_last('loss'):.4f}\",\n",
    "                                 dev_loss = f\"{dev_metrics.get_last('loss'):.4f}\",\n",
    "                                 dev_score = f\"{dev_metrics.last_display():.4f}\")\n",
    "\n",
    "                if hyperopt:\n",
    "                    hyperopt.report(dev_metrics.last_display(), epoch)\n",
    "\n",
    "                if earlystop is not None and earlystop(model, dev_metrics.early_stopping()):\n",
    "                    model = earlystop.best_state\n",
    "                    break\n",
    "            except Exception:\n",
    "                loop.set_postfix(epoch_loss = metrics.get_last('loss'))\n",
    "            finally:\n",
    "                loop.refresh()\n",
    "        metrics.scores = scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mtl_epoch(model: base.ModelType, loss_f: base.Callable, loss_weights: base.DataType, optimizer: base.Callable,\n",
    "               metrics: object, batchers: base.List[base.Batch], batch_count: int, dataset_weights: base.List[float],\n",
    "               taskid2name: dict, epoch_no: int, clip: float = None, gpu: bool = True, **kwargs) -> None:\n",
    "    \"\"\"\n",
    "    Train one epoch of an MTL training loop.\n",
    "\n",
    "    :model (base.ModelType): Model in the process of being trained.\n",
    "    :loss_f (base.Callable): The loss function being used.\n",
    "    :loss_weights (base.DataType): Determines relative task importance When using multiple input/output functions.\n",
    "    :optimizer (base.Callable): The optimizer function used.\n",
    "    :metrics (object): Initialized Metrics object.\n",
    "    :batchers (base.List[base.Batch]): A list of batched objects.\n",
    "    :batch_count (int): The number of batchers to go through in each epoch.\n",
    "    :dataset_weights (base.List[float]): The probability with which each dataset is chosen to be trained on.\n",
    "    :taskid2name (dict): Dictionary mapping task ID to dataset name.\n",
    "    :epoch_no (int): The iteration of the epoch.\n",
    "    :clip (float, default = None): Use gradient clipping.\n",
    "    \"\"\"\n",
    "    with tqdm(range(batch_count), desc = 'Batch', leave = False) as loop:\n",
    "        label_count = 0\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for i, b in enumerate(loop):\n",
    "            # Select task and get batch\n",
    "            task_id = np.random.choice(range(len(batchers)), p = dataset_weights)\n",
    "            X, y = next(iter(batchers[task_id]))\n",
    "\n",
    "            if gpu:\n",
    "                X = X.cuda()\n",
    "                y = y.cuda()\n",
    "\n",
    "            # Do model training\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            scores = model(X, task_id, **kwargs)\n",
    "            loss = loss_f(scores, y) * loss_weights[task_id]\n",
    "            loss.backward()\n",
    "\n",
    "            if clip is not None:\n",
    "                torch.nn.utils.clip_grad_norm(model.parameters(), clip)  # Prevent exploding gradients\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            metrics.compute(torch.argmax(scores, dim = 1).tolist(), y.tolist())\n",
    "            label_count += len(y.cpu().tolist())\n",
    "            epoch_loss += loss.data.item()\n",
    "            metrics.loss = loss.data.item() / len(y)\n",
    "\n",
    "            # Write batch info\n",
    "            task_name = taskid2name[task_id]\n",
    "            #mtl_batch_writer(model = model, batch = i, metrics = metrics, task_name = task_name, epoch = epoch_no,\n",
    "            #                 **kwargs)\n",
    "\n",
    "            loop.set_postfix(batch_loss = f\"{metrics.get_last('loss'):.4f}\",\n",
    "                             epoch_loss = f\"{epoch_loss / label_count:.4f}\",\n",
    "                             task_score = f\"{metrics.last_display():.4f}\",\n",
    "                             task = task_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}