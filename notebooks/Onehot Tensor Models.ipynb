{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import mlearn.base as base\n",
    "from mlearn.base import Field\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mlearn.utils.pipeline import process_and_batch\n",
    "from mlearn.data_processing.data import GeneralDataset\n",
    "import mlearn.modeling.onehot as oh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Test (train): 1914it [00:00, 39755.65it/s]\n",
      "Loading Test (test): 478it [00:00, 11693.38it/s]\n"
     ]
    }
   ],
   "source": [
    "text_field = Field('text', train = True, label = False, ignore = False, ix = 5, cname = 'text')\n",
    "label_field = Field('label', train = False, label = True, cname = 'label', ignore = False, ix = 4)\n",
    "ignore_field = Field('ignore', train = False, label = False, cname = 'ignore', ignore = True)\n",
    "\n",
    "fields = [text_field, label_field]\n",
    "dataset = GeneralDataset(data_dir = '~/PhD/projects/tools/mlearn/tests/',\n",
    "                         ftype = 'csv', fields = fields, train = 'garcia_stormfront_train.tsv', dev = None,\n",
    "                         test = 'garcia_stormfront_test.tsv', train_labels = None, tokenizer = lambda x: x.split(),\n",
    "                         lower = True, preprocessor = None, transformations = None,\n",
    "                         label_processor = None, sep = '\\t', name = 'Test')\n",
    "dataset.load('train')\n",
    "dataset.load('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the documents and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building vocabulary: 100%|██████████| 1914/1914 [00:00<00:00, 55954.85it/s]\n",
      "Encoding vocabulary: 100%|██████████| 6291/6291 [00:00<00:00, 121708.33it/s]\n",
      "Encode label vocab: 100%|██████████| 2/2 [00:00<00:00, 4522.16it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset.build_token_vocab(dataset.data)\n",
    "dataset.build_label_vocab(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = process_and_batch(dataset, dataset.data, 32, onehot = True)\n",
    "test = process_and_batch(dataset, dataset.test, 32, onehot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 60\n",
      "Length of first batch: 32\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of batches:\", len(train))\n",
    "print(\"Length of first batch:\", len(train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = oh.RNNClassifier(dataset.vocab_size(), hidden_dim = 128, embedding_dim = dataset.vocab_size(), output_dim = 3, batch_first = True)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [02:10<00:00,  2.17s/it, accuracy=0.423, loss=0.125] \n"
     ]
    }
   ],
   "source": [
    "with tqdm(train) as loop:\n",
    "    for X, y in loop:\n",
    "        res = model(X.long())\n",
    "        l = loss(res, y)\n",
    "        \n",
    "        acc = accuracy_score(res.argmax(dim=1).cpu(), y.cpu())\n",
    "\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        loop.set_postfix(loss = l.data.item() / X.shape[0], accuracy = acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = oh.LSTMClassifier(dataset.vocab_size(), hidden_dim = 128, embedding_dim = 128, output_dim = 3, num_layers = 1, batch_first = True)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /Users/zeerakw/.virtualenvs/mlearn/lib/python3.7/site-packages/mlearn-0.0.1-py3.7.egg/mlearn/modeling/onehot.py(45)forward()\n",
      "-> sequence = sequence.float()\n"
     ]
    }
   ],
   "source": [
    "with tqdm(train) as loop:\n",
    "    for X, y in loop:\n",
    "        res = model(X.long())\n",
    "        l = loss(res, y)\n",
    "        \n",
    "        acc = accuracy_score(res.argmax(dim=1).cpu(), y.cpu())\n",
    "\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        loop.set_postfix(loss = l.data.item() / X.shape[0], accuracy = acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = oh.MLPClassifier(dataset.vocab_size(), hidden_dim = 128, embedding_dim = 128, output_dim = 3, batch_first = True)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(train) as loop:\n",
    "    for X, y in loop:\n",
    "        res = model(X.long())\n",
    "        l = loss(res, y)\n",
    "        \n",
    "        acc = accuracy_score(res.argmax(dim=1).cpu(), y.cpu())\n",
    "\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        loop.set_postfix(loss = l.data.item() / X.shape[0], accuracy = acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = oh.CNNClassifier(window_sizes = [2,3,4], num_filters = 128, max_feats = dataset.vocab_size(), \n",
    "                      output_dim = 3, vocab_size = dataset.vocab_size(), hidden_dim = 128,\n",
    "                      batch_first = True)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(train) as loop:\n",
    "    for X, y in loop:\n",
    "        res = model(X.long())\n",
    "        l = loss(res, y)\n",
    "        \n",
    "        acc = accuracy_score(res.argmax(dim=1).cpu(), y.cpu())\n",
    "\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        loop.set_postfix(loss = l.data.item() / X.shape[0], accuracy = acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
